{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASSIGNMENT-16 ON NEURAL NETWORK FORESTFIRES.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K7T_s-HpVldw"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fire = pd.read_csv(\"/content/forestfires.csv\")\n",
        "fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "wedlfByuVpgZ",
        "outputId": "ec78a46f-2a49-4d0c-a799-a4c264f8ac22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
              "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
              "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
              "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
              "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
              "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
              "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
              "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
              "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
              "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
              "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
              "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
              "\n",
              "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
              "0           0         0         0         1         0         0         0   \n",
              "1           0         0         0         0         0         0         1   \n",
              "2           0         0         0         0         0         0         1   \n",
              "3           0         0         0         1         0         0         0   \n",
              "4           0         0         0         1         0         0         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "512         0         0         0         0         0         0         0   \n",
              "513         0         0         0         0         0         0         0   \n",
              "514         0         0         0         0         0         0         0   \n",
              "515         0         0         0         0         0         0         0   \n",
              "516         0         0         0         0         0         1         0   \n",
              "\n",
              "     monthsep  size_category  \n",
              "0           0          small  \n",
              "1           0          small  \n",
              "2           0          small  \n",
              "3           0          small  \n",
              "4           0          small  \n",
              "..        ...            ...  \n",
              "512         0          large  \n",
              "513         0          large  \n",
              "514         0          large  \n",
              "515         0          small  \n",
              "516         0          small  \n",
              "\n",
              "[517 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5430c97c-bc1a-4a93-bdf1-fb935df1743b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5430c97c-bc1a-4a93-bdf1-fb935df1743b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5430c97c-bc1a-4a93-bdf1-fb935df1743b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5430c97c-bc1a-4a93-bdf1-fb935df1743b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fire.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEY9sBC0V7E5",
        "outputId": "03f63c5e-5186-45e3-f765-7dbf060e8730"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 31 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   month          517 non-null    object \n",
            " 1   day            517 non-null    object \n",
            " 2   FFMC           517 non-null    float64\n",
            " 3   DMC            517 non-null    float64\n",
            " 4   DC             517 non-null    float64\n",
            " 5   ISI            517 non-null    float64\n",
            " 6   temp           517 non-null    float64\n",
            " 7   RH             517 non-null    int64  \n",
            " 8   wind           517 non-null    float64\n",
            " 9   rain           517 non-null    float64\n",
            " 10  area           517 non-null    float64\n",
            " 11  dayfri         517 non-null    int64  \n",
            " 12  daymon         517 non-null    int64  \n",
            " 13  daysat         517 non-null    int64  \n",
            " 14  daysun         517 non-null    int64  \n",
            " 15  daythu         517 non-null    int64  \n",
            " 16  daytue         517 non-null    int64  \n",
            " 17  daywed         517 non-null    int64  \n",
            " 18  monthapr       517 non-null    int64  \n",
            " 19  monthaug       517 non-null    int64  \n",
            " 20  monthdec       517 non-null    int64  \n",
            " 21  monthfeb       517 non-null    int64  \n",
            " 22  monthjan       517 non-null    int64  \n",
            " 23  monthjul       517 non-null    int64  \n",
            " 24  monthjun       517 non-null    int64  \n",
            " 25  monthmar       517 non-null    int64  \n",
            " 26  monthmay       517 non-null    int64  \n",
            " 27  monthnov       517 non-null    int64  \n",
            " 28  monthoct       517 non-null    int64  \n",
            " 29  monthsep       517 non-null    int64  \n",
            " 30  size_category  517 non-null    object \n",
            "dtypes: float64(8), int64(20), object(3)\n",
            "memory usage: 125.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fire.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "uiCZD71sWAXG",
        "outputId": "d59b67ec-ea29-44ed-b45a-eddb830a125f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          count        mean         std   min    25%     50%     75%      max\n",
              "FFMC      517.0   90.644681    5.520111  18.7   90.2   91.60   92.90    96.20\n",
              "DMC       517.0  110.872340   64.046482   1.1   68.6  108.30  142.40   291.30\n",
              "DC        517.0  547.940039  248.066192   7.9  437.7  664.20  713.90   860.60\n",
              "ISI       517.0    9.021663    4.559477   0.0    6.5    8.40   10.80    56.10\n",
              "temp      517.0   18.889168    5.806625   2.2   15.5   19.30   22.80    33.30\n",
              "RH        517.0   44.288201   16.317469  15.0   33.0   42.00   53.00   100.00\n",
              "wind      517.0    4.017602    1.791653   0.4    2.7    4.00    4.90     9.40\n",
              "rain      517.0    0.021663    0.295959   0.0    0.0    0.00    0.00     6.40\n",
              "area      517.0   12.847292   63.655818   0.0    0.0    0.52    6.57  1090.84\n",
              "dayfri    517.0    0.164410    0.371006   0.0    0.0    0.00    0.00     1.00\n",
              "daymon    517.0    0.143133    0.350548   0.0    0.0    0.00    0.00     1.00\n",
              "daysat    517.0    0.162476    0.369244   0.0    0.0    0.00    0.00     1.00\n",
              "daysun    517.0    0.183752    0.387657   0.0    0.0    0.00    0.00     1.00\n",
              "daythu    517.0    0.117988    0.322907   0.0    0.0    0.00    0.00     1.00\n",
              "daytue    517.0    0.123791    0.329662   0.0    0.0    0.00    0.00     1.00\n",
              "daywed    517.0    0.104449    0.306138   0.0    0.0    0.00    0.00     1.00\n",
              "monthapr  517.0    0.017408    0.130913   0.0    0.0    0.00    0.00     1.00\n",
              "monthaug  517.0    0.355899    0.479249   0.0    0.0    0.00    1.00     1.00\n",
              "monthdec  517.0    0.017408    0.130913   0.0    0.0    0.00    0.00     1.00\n",
              "monthfeb  517.0    0.038685    0.193029   0.0    0.0    0.00    0.00     1.00\n",
              "monthjan  517.0    0.003868    0.062137   0.0    0.0    0.00    0.00     1.00\n",
              "monthjul  517.0    0.061896    0.241199   0.0    0.0    0.00    0.00     1.00\n",
              "monthjun  517.0    0.032882    0.178500   0.0    0.0    0.00    0.00     1.00\n",
              "monthmar  517.0    0.104449    0.306138   0.0    0.0    0.00    0.00     1.00\n",
              "monthmay  517.0    0.003868    0.062137   0.0    0.0    0.00    0.00     1.00\n",
              "monthnov  517.0    0.001934    0.043980   0.0    0.0    0.00    0.00     1.00\n",
              "monthoct  517.0    0.029014    0.168007   0.0    0.0    0.00    0.00     1.00\n",
              "monthsep  517.0    0.332689    0.471632   0.0    0.0    0.00    1.00     1.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8beb789-3d4b-4d8d-8bbb-01bc642b909a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FFMC</th>\n",
              "      <td>517.0</td>\n",
              "      <td>90.644681</td>\n",
              "      <td>5.520111</td>\n",
              "      <td>18.7</td>\n",
              "      <td>90.2</td>\n",
              "      <td>91.60</td>\n",
              "      <td>92.90</td>\n",
              "      <td>96.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DMC</th>\n",
              "      <td>517.0</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>1.1</td>\n",
              "      <td>68.6</td>\n",
              "      <td>108.30</td>\n",
              "      <td>142.40</td>\n",
              "      <td>291.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DC</th>\n",
              "      <td>517.0</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>7.9</td>\n",
              "      <td>437.7</td>\n",
              "      <td>664.20</td>\n",
              "      <td>713.90</td>\n",
              "      <td>860.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISI</th>\n",
              "      <td>517.0</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.40</td>\n",
              "      <td>10.80</td>\n",
              "      <td>56.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temp</th>\n",
              "      <td>517.0</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>2.2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>19.30</td>\n",
              "      <td>22.80</td>\n",
              "      <td>33.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RH</th>\n",
              "      <td>517.0</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>15.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>42.00</td>\n",
              "      <td>53.00</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wind</th>\n",
              "      <td>517.0</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.90</td>\n",
              "      <td>9.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rain</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area</th>\n",
              "      <td>517.0</td>\n",
              "      <td>12.847292</td>\n",
              "      <td>63.655818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.52</td>\n",
              "      <td>6.57</td>\n",
              "      <td>1090.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dayfri</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.164410</td>\n",
              "      <td>0.371006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daymon</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.143133</td>\n",
              "      <td>0.350548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daysat</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>0.369244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daysun</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.387657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daythu</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.117988</td>\n",
              "      <td>0.322907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daytue</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.329662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daywed</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthapr</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthaug</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.355899</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthdec</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthfeb</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.038685</td>\n",
              "      <td>0.193029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthjan</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthjul</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.241199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthjun</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthmar</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthmay</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthnov</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.043980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthoct</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.168007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthsep</th>\n",
              "      <td>517.0</td>\n",
              "      <td>0.332689</td>\n",
              "      <td>0.471632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8beb789-3d4b-4d8d-8bbb-01bc642b909a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8beb789-3d4b-4d8d-8bbb-01bc642b909a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8beb789-3d4b-4d8d-8bbb-01bc642b909a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "fire['size_category']= label_encoder.fit_transform(fire['size_category'])"
      ],
      "metadata": {
        "id": "HHm7rFFpWEmK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fire=fire.drop(columns=['month','day'], axis=1)\n",
        "fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "QZrIIRziWOtk",
        "outputId": "5eedd770-f700-46ce-95f1-6cd5d799ca3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
              "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
              "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
              "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
              "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
              "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
              "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
              "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
              "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
              "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
              "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
              "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
              "\n",
              "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
              "0           0         0         0         0         1         0         0   \n",
              "1           0         0         0         0         0         0         0   \n",
              "2           0         0         0         0         0         0         0   \n",
              "3           0         0         0         0         1         0         0   \n",
              "4           0         0         0         0         1         0         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "512         0         0         0         0         0         0         0   \n",
              "513         0         0         0         0         0         0         0   \n",
              "514         0         0         0         0         0         0         0   \n",
              "515         0         0         0         0         0         0         0   \n",
              "516         0         0         0         0         0         0         1   \n",
              "\n",
              "     monthoct  monthsep  size_category  \n",
              "0           0         0              1  \n",
              "1           1         0              1  \n",
              "2           1         0              1  \n",
              "3           0         0              1  \n",
              "4           0         0              1  \n",
              "..        ...       ...            ...  \n",
              "512         0         0              0  \n",
              "513         0         0              0  \n",
              "514         0         0              0  \n",
              "515         0         0              1  \n",
              "516         0         0              1  \n",
              "\n",
              "[517 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d818c2b3-103c-484f-b7b2-c632cace7dc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d818c2b3-103c-484f-b7b2-c632cace7dc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d818c2b3-103c-484f-b7b2-c632cace7dc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d818c2b3-103c-484f-b7b2-c632cace7dc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fire.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vIXvt9BWWHt",
        "outputId": "71c4c403-88d5-486f-98e7-b28c910996a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 29 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   FFMC           517 non-null    float64\n",
            " 1   DMC            517 non-null    float64\n",
            " 2   DC             517 non-null    float64\n",
            " 3   ISI            517 non-null    float64\n",
            " 4   temp           517 non-null    float64\n",
            " 5   RH             517 non-null    int64  \n",
            " 6   wind           517 non-null    float64\n",
            " 7   rain           517 non-null    float64\n",
            " 8   area           517 non-null    float64\n",
            " 9   dayfri         517 non-null    int64  \n",
            " 10  daymon         517 non-null    int64  \n",
            " 11  daysat         517 non-null    int64  \n",
            " 12  daysun         517 non-null    int64  \n",
            " 13  daythu         517 non-null    int64  \n",
            " 14  daytue         517 non-null    int64  \n",
            " 15  daywed         517 non-null    int64  \n",
            " 16  monthapr       517 non-null    int64  \n",
            " 17  monthaug       517 non-null    int64  \n",
            " 18  monthdec       517 non-null    int64  \n",
            " 19  monthfeb       517 non-null    int64  \n",
            " 20  monthjan       517 non-null    int64  \n",
            " 21  monthjul       517 non-null    int64  \n",
            " 22  monthjun       517 non-null    int64  \n",
            " 23  monthmar       517 non-null    int64  \n",
            " 24  monthmay       517 non-null    int64  \n",
            " 25  monthnov       517 non-null    int64  \n",
            " 26  monthoct       517 non-null    int64  \n",
            " 27  monthsep       517 non-null    int64  \n",
            " 28  size_category  517 non-null    int64  \n",
            "dtypes: float64(8), int64(21)\n",
            "memory usage: 117.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = fire.iloc[:,0:-1]\n",
        "y = fire['size_category']"
      ],
      "metadata": {
        "id": "Mdm4Si69WbfX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "XKqTtxelWhEN",
        "outputId": "06a6996a-5368-4f7e-fbf4-a959be60ed06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
              "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
              "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
              "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
              "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
              "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
              "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
              "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
              "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
              "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
              "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
              "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
              "\n",
              "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
              "0           0         0         0         0         0         1         0   \n",
              "1           0         0         0         0         0         0         0   \n",
              "2           0         0         0         0         0         0         0   \n",
              "3           0         0         0         0         0         1         0   \n",
              "4           0         0         0         0         0         1         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "512         0         0         0         0         0         0         0   \n",
              "513         0         0         0         0         0         0         0   \n",
              "514         0         0         0         0         0         0         0   \n",
              "515         0         0         0         0         0         0         0   \n",
              "516         0         0         0         0         0         0         0   \n",
              "\n",
              "     monthnov  monthoct  monthsep  \n",
              "0           0         0         0  \n",
              "1           0         1         0  \n",
              "2           0         1         0  \n",
              "3           0         0         0  \n",
              "4           0         0         0  \n",
              "..        ...       ...       ...  \n",
              "512         0         0         0  \n",
              "513         0         0         0  \n",
              "514         0         0         0  \n",
              "515         0         0         0  \n",
              "516         1         0         0  \n",
              "\n",
              "[517 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a1336d9-add9-45db-9df1-9cea4651ecf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>...</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a1336d9-add9-45db-9df1-9cea4651ecf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a1336d9-add9-45db-9df1-9cea4651ecf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a1336d9-add9-45db-9df1-9cea4651ecf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtKAit6cWkO-",
        "outputId": "f5aea301-bdda-456a-dc0d-09e29c6e30d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "512    0\n",
              "513    0\n",
              "514    0\n",
              "515    1\n",
              "516    1\n",
              "Name: size_category, Length: 517, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)"
      ],
      "metadata": {
        "id": "qTrWsTe5Wmrq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(42, input_dim=28, activation='relu'))\n",
        "model.add(Dense(28, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "IiIUbkpXWubd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5g5YCtpIW66A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history=model.fit(x_train,y_train, validation_split=0.33, epochs=180, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYuBgl-2XAAc",
        "outputId": "1e32b99a-e136-48a0-b2dd-3597bd2b8260"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/180\n",
            "28/28 [==============================] - 2s 21ms/step - loss: 25.1010 - accuracy: 0.4601 - val_loss: 8.8953 - val_accuracy: 0.7372\n",
            "Epoch 2/180\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 3.5465 - accuracy: 0.7355 - val_loss: 2.5108 - val_accuracy: 0.6569\n",
            "Epoch 3/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1.3545 - accuracy: 0.7536 - val_loss: 1.2708 - val_accuracy: 0.6350\n",
            "Epoch 4/180\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7164 - accuracy: 0.7717 - val_loss: 0.9422 - val_accuracy: 0.8175\n",
            "Epoch 5/180\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.8079 - accuracy: 0.7826 - val_loss: 1.0068 - val_accuracy: 0.5912\n",
            "Epoch 6/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8043 - val_loss: 0.4466 - val_accuracy: 0.8467\n",
            "Epoch 7/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8623 - val_loss: 0.5248 - val_accuracy: 0.8540\n",
            "Epoch 8/180\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3171 - accuracy: 0.8587 - val_loss: 0.5082 - val_accuracy: 0.8540\n",
            "Epoch 9/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8732 - val_loss: 0.3103 - val_accuracy: 0.8905\n",
            "Epoch 10/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8659 - val_loss: 0.4107 - val_accuracy: 0.8759\n",
            "Epoch 11/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9022 - val_loss: 0.2535 - val_accuracy: 0.9051\n",
            "Epoch 12/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9094 - val_loss: 0.2800 - val_accuracy: 0.8978\n",
            "Epoch 13/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9130 - val_loss: 0.2486 - val_accuracy: 0.9051\n",
            "Epoch 14/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9167 - val_loss: 0.4624 - val_accuracy: 0.8759\n",
            "Epoch 15/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8841 - val_loss: 0.3809 - val_accuracy: 0.8978\n",
            "Epoch 16/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8877 - val_loss: 0.1992 - val_accuracy: 0.9124\n",
            "Epoch 17/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9529 - val_loss: 0.1921 - val_accuracy: 0.9124\n",
            "Epoch 18/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9130 - val_loss: 0.2037 - val_accuracy: 0.9124\n",
            "Epoch 19/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9203 - val_loss: 0.4791 - val_accuracy: 0.8905\n",
            "Epoch 20/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8986 - val_loss: 0.1644 - val_accuracy: 0.9343\n",
            "Epoch 21/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8877 - val_loss: 0.7444 - val_accuracy: 0.5985\n",
            "Epoch 22/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8949 - val_loss: 0.4320 - val_accuracy: 0.8905\n",
            "Epoch 23/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9529 - val_loss: 0.1595 - val_accuracy: 0.9270\n",
            "Epoch 24/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9457 - val_loss: 0.1340 - val_accuracy: 0.9270\n",
            "Epoch 25/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9529 - val_loss: 0.1739 - val_accuracy: 0.9270\n",
            "Epoch 26/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9420 - val_loss: 0.1332 - val_accuracy: 0.9343\n",
            "Epoch 27/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9312 - val_loss: 0.2072 - val_accuracy: 0.9124\n",
            "Epoch 28/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.9239 - val_loss: 0.2642 - val_accuracy: 0.9051\n",
            "Epoch 29/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9457 - val_loss: 0.2206 - val_accuracy: 0.9124\n",
            "Epoch 30/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9529 - val_loss: 0.1511 - val_accuracy: 0.9197\n",
            "Epoch 31/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9565 - val_loss: 0.1949 - val_accuracy: 0.9124\n",
            "Epoch 32/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9529 - val_loss: 0.3049 - val_accuracy: 0.9051\n",
            "Epoch 33/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9384 - val_loss: 0.1034 - val_accuracy: 0.9343\n",
            "Epoch 34/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9746 - val_loss: 0.1141 - val_accuracy: 0.9343\n",
            "Epoch 35/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9710 - val_loss: 0.1005 - val_accuracy: 0.9489\n",
            "Epoch 36/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9855 - val_loss: 0.1044 - val_accuracy: 0.9343\n",
            "Epoch 37/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9891 - val_loss: 0.0902 - val_accuracy: 0.9562\n",
            "Epoch 38/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9565 - val_loss: 0.0892 - val_accuracy: 0.9562\n",
            "Epoch 39/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9746 - val_loss: 0.1273 - val_accuracy: 0.9343\n",
            "Epoch 40/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9746 - val_loss: 0.1099 - val_accuracy: 0.9781\n",
            "Epoch 41/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9565 - val_loss: 0.0795 - val_accuracy: 0.9781\n",
            "Epoch 42/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9638 - val_loss: 0.1488 - val_accuracy: 0.9489\n",
            "Epoch 43/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9674 - val_loss: 0.1712 - val_accuracy: 0.9197\n",
            "Epoch 44/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9710 - val_loss: 0.1597 - val_accuracy: 0.9197\n",
            "Epoch 45/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9819 - val_loss: 0.3358 - val_accuracy: 0.8978\n",
            "Epoch 46/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9674 - val_loss: 0.1027 - val_accuracy: 0.9416\n",
            "Epoch 47/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9819 - val_loss: 0.1293 - val_accuracy: 0.9489\n",
            "Epoch 48/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9746 - val_loss: 0.2331 - val_accuracy: 0.9124\n",
            "Epoch 49/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9239 - val_loss: 0.1059 - val_accuracy: 0.9635\n",
            "Epoch 50/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1238 - accuracy: 0.9601 - val_loss: 0.3118 - val_accuracy: 0.8905\n",
            "Epoch 51/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.9058 - val_loss: 0.1283 - val_accuracy: 0.9562\n",
            "Epoch 52/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9493 - val_loss: 0.0954 - val_accuracy: 0.9562\n",
            "Epoch 53/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.2578 - val_accuracy: 0.9197\n",
            "Epoch 54/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9565 - val_loss: 0.3730 - val_accuracy: 0.9124\n",
            "Epoch 55/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9529 - val_loss: 0.0931 - val_accuracy: 0.9635\n",
            "Epoch 56/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9710 - val_loss: 0.0687 - val_accuracy: 0.9708\n",
            "Epoch 57/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9746 - val_loss: 0.0567 - val_accuracy: 0.9781\n",
            "Epoch 58/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.0823 - val_accuracy: 0.9635\n",
            "Epoch 59/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 0.1220 - val_accuracy: 0.9635\n",
            "Epoch 60/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9783 - val_loss: 0.1119 - val_accuracy: 0.9635\n",
            "Epoch 61/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9819 - val_loss: 0.1151 - val_accuracy: 0.9635\n",
            "Epoch 62/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9928 - val_loss: 0.0628 - val_accuracy: 0.9708\n",
            "Epoch 63/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.0857 - val_accuracy: 0.9635\n",
            "Epoch 64/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.0659 - val_accuracy: 0.9781\n",
            "Epoch 65/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 0.1491 - val_accuracy: 0.9489\n",
            "Epoch 66/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9891 - val_loss: 0.1200 - val_accuracy: 0.9489\n",
            "Epoch 67/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9384 - val_loss: 0.1909 - val_accuracy: 0.9270\n",
            "Epoch 68/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9275 - val_loss: 0.5424 - val_accuracy: 0.9051\n",
            "Epoch 69/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8913 - val_loss: 0.4435 - val_accuracy: 0.9124\n",
            "Epoch 70/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9565 - val_loss: 0.0824 - val_accuracy: 0.9708\n",
            "Epoch 71/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9783 - val_loss: 0.0662 - val_accuracy: 0.9781\n",
            "Epoch 72/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9710 - val_loss: 0.1071 - val_accuracy: 0.9635\n",
            "Epoch 73/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9928 - val_loss: 0.0876 - val_accuracy: 0.9635\n",
            "Epoch 74/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9638 - val_loss: 0.1397 - val_accuracy: 0.9343\n",
            "Epoch 75/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9601 - val_loss: 0.3537 - val_accuracy: 0.9197\n",
            "Epoch 76/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8659 - val_loss: 0.6218 - val_accuracy: 0.9051\n",
            "Epoch 77/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9638 - val_loss: 0.0502 - val_accuracy: 0.9781\n",
            "Epoch 78/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0450 - val_accuracy: 0.9781\n",
            "Epoch 79/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9891 - val_loss: 0.0614 - val_accuracy: 0.9781\n",
            "Epoch 80/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9855 - val_loss: 0.0900 - val_accuracy: 0.9635\n",
            "Epoch 81/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9891 - val_loss: 0.0400 - val_accuracy: 0.9854\n",
            "Epoch 82/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0424 - val_accuracy: 0.9781\n",
            "Epoch 83/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9855 - val_loss: 0.0451 - val_accuracy: 0.9781\n",
            "Epoch 84/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0546 - val_accuracy: 0.9708\n",
            "Epoch 85/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0595 - val_accuracy: 0.9781\n",
            "Epoch 86/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9855 - val_loss: 0.0490 - val_accuracy: 0.9708\n",
            "Epoch 87/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0397 - val_accuracy: 0.9781\n",
            "Epoch 88/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.0446 - val_accuracy: 0.9854\n",
            "Epoch 89/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0981 - val_accuracy: 0.9635\n",
            "Epoch 90/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9819 - val_loss: 0.0788 - val_accuracy: 0.9562\n",
            "Epoch 91/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9746 - val_loss: 0.1389 - val_accuracy: 0.9635\n",
            "Epoch 92/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9746 - val_loss: 0.0410 - val_accuracy: 0.9854\n",
            "Epoch 93/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9746 - val_loss: 0.1264 - val_accuracy: 0.9635\n",
            "Epoch 94/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 0.0496 - val_accuracy: 0.9708\n",
            "Epoch 95/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9855 - val_loss: 0.0630 - val_accuracy: 0.9708\n",
            "Epoch 96/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9819 - val_loss: 0.1290 - val_accuracy: 0.9635\n",
            "Epoch 97/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9855 - val_loss: 0.0443 - val_accuracy: 0.9781\n",
            "Epoch 98/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9783 - val_loss: 0.1147 - val_accuracy: 0.9635\n",
            "Epoch 99/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9855 - val_loss: 0.3167 - val_accuracy: 0.9416\n",
            "Epoch 100/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9384 - val_loss: 0.0667 - val_accuracy: 0.9781\n",
            "Epoch 101/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.0933 - val_accuracy: 0.9708\n",
            "Epoch 102/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.0990 - val_accuracy: 0.9562\n",
            "Epoch 103/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0602 - val_accuracy: 0.9708\n",
            "Epoch 104/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9855 - val_loss: 0.0656 - val_accuracy: 0.9781\n",
            "Epoch 105/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9855 - val_loss: 0.1342 - val_accuracy: 0.9635\n",
            "Epoch 106/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 0.1102 - val_accuracy: 0.9635\n",
            "Epoch 107/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0461 - val_accuracy: 0.9854\n",
            "Epoch 108/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9638 - val_loss: 0.1204 - val_accuracy: 0.9635\n",
            "Epoch 109/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9601 - val_loss: 0.1679 - val_accuracy: 0.9635\n",
            "Epoch 110/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9783 - val_loss: 0.0689 - val_accuracy: 0.9708\n",
            "Epoch 111/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9855 - val_loss: 0.0921 - val_accuracy: 0.9708\n",
            "Epoch 112/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 0.0459 - val_accuracy: 0.9854\n",
            "Epoch 113/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9783 - val_loss: 0.0436 - val_accuracy: 0.9854\n",
            "Epoch 114/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9746 - val_loss: 0.0611 - val_accuracy: 0.9708\n",
            "Epoch 115/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9783 - val_loss: 0.0373 - val_accuracy: 0.9854\n",
            "Epoch 116/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9710 - val_loss: 0.1261 - val_accuracy: 0.9635\n",
            "Epoch 117/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9710 - val_loss: 0.0507 - val_accuracy: 0.9781\n",
            "Epoch 118/180\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9855 - val_loss: 0.0546 - val_accuracy: 0.9708\n",
            "Epoch 119/180\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9819 - val_loss: 0.0340 - val_accuracy: 0.9854\n",
            "Epoch 120/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9783 - val_loss: 0.2351 - val_accuracy: 0.9270\n",
            "Epoch 121/180\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9384 - val_loss: 0.1208 - val_accuracy: 0.9708\n",
            "Epoch 122/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9565 - val_loss: 0.2106 - val_accuracy: 0.9562\n",
            "Epoch 123/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.1104 - val_accuracy: 0.9708\n",
            "Epoch 124/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9891 - val_loss: 0.0664 - val_accuracy: 0.9635\n",
            "Epoch 125/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0862 - val_accuracy: 0.9708\n",
            "Epoch 126/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9819 - val_loss: 0.0797 - val_accuracy: 0.9781\n",
            "Epoch 127/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9783 - val_loss: 0.1735 - val_accuracy: 0.9635\n",
            "Epoch 128/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9964 - val_loss: 0.1206 - val_accuracy: 0.9635\n",
            "Epoch 129/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9708\n",
            "Epoch 130/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9855 - val_loss: 0.0639 - val_accuracy: 0.9708\n",
            "Epoch 131/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9819 - val_loss: 0.1242 - val_accuracy: 0.9635\n",
            "Epoch 132/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.1127 - val_accuracy: 0.9635\n",
            "Epoch 133/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.0713 - val_accuracy: 0.9708\n",
            "Epoch 134/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9855 - val_loss: 0.0462 - val_accuracy: 0.9781\n",
            "Epoch 135/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9601 - val_loss: 0.5271 - val_accuracy: 0.9197\n",
            "Epoch 136/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.9348 - val_loss: 0.0641 - val_accuracy: 0.9708\n",
            "Epoch 137/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9565 - val_loss: 0.0418 - val_accuracy: 0.9854\n",
            "Epoch 138/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9855 - val_loss: 0.1614 - val_accuracy: 0.9635\n",
            "Epoch 139/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9855 - val_loss: 0.0829 - val_accuracy: 0.9781\n",
            "Epoch 140/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.1406 - val_accuracy: 0.9635\n",
            "Epoch 141/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.2230 - val_accuracy: 0.9635\n",
            "Epoch 142/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9710 - val_loss: 0.0636 - val_accuracy: 0.9781\n",
            "Epoch 143/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 0.0882 - val_accuracy: 0.9708\n",
            "Epoch 144/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 0.1077 - val_accuracy: 0.9562\n",
            "Epoch 145/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9601 - val_loss: 0.1106 - val_accuracy: 0.9708\n",
            "Epoch 146/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9674 - val_loss: 0.0568 - val_accuracy: 0.9708\n",
            "Epoch 147/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9819 - val_loss: 0.2150 - val_accuracy: 0.9635\n",
            "Epoch 148/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0952 - val_accuracy: 0.9708\n",
            "Epoch 149/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9674 - val_loss: 0.0583 - val_accuracy: 0.9708\n",
            "Epoch 150/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9783 - val_loss: 0.1658 - val_accuracy: 0.9635\n",
            "Epoch 151/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9746 - val_loss: 0.0687 - val_accuracy: 0.9781\n",
            "Epoch 152/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9855 - val_loss: 0.0640 - val_accuracy: 0.9708\n",
            "Epoch 153/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9819 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
            "Epoch 154/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
            "Epoch 155/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.1162 - val_accuracy: 0.9708\n",
            "Epoch 156/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9855 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
            "Epoch 157/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9819 - val_loss: 0.0713 - val_accuracy: 0.9781\n",
            "Epoch 158/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 0.2016 - val_accuracy: 0.9635\n",
            "Epoch 159/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 0.1379 - val_accuracy: 0.9708\n",
            "Epoch 160/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.1151 - val_accuracy: 0.9708\n",
            "Epoch 161/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.0566 - val_accuracy: 0.9708\n",
            "Epoch 162/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9855 - val_loss: 0.0583 - val_accuracy: 0.9781\n",
            "Epoch 163/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 0.1399 - val_accuracy: 0.9635\n",
            "Epoch 164/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9891 - val_loss: 0.1036 - val_accuracy: 0.9708\n",
            "Epoch 165/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9710 - val_loss: 0.0453 - val_accuracy: 0.9854\n",
            "Epoch 166/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9819 - val_loss: 0.2843 - val_accuracy: 0.9635\n",
            "Epoch 167/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9601 - val_loss: 0.0912 - val_accuracy: 0.9708\n",
            "Epoch 168/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9819 - val_loss: 0.0859 - val_accuracy: 0.9708\n",
            "Epoch 169/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9746 - val_loss: 0.2006 - val_accuracy: 0.9635\n",
            "Epoch 170/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9384 - val_loss: 0.0587 - val_accuracy: 0.9781\n",
            "Epoch 171/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.2587 - val_accuracy: 0.9635\n",
            "Epoch 172/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9783 - val_loss: 0.0984 - val_accuracy: 0.9781\n",
            "Epoch 173/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9746 - val_loss: 0.1118 - val_accuracy: 0.9489\n",
            "Epoch 174/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9674 - val_loss: 0.0880 - val_accuracy: 0.9708\n",
            "Epoch 175/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.0448 - val_accuracy: 0.9854\n",
            "Epoch 176/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9891 - val_loss: 0.1894 - val_accuracy: 0.9635\n",
            "Epoch 177/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.1623 - val_accuracy: 0.9635\n",
            "Epoch 178/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9746 - val_loss: 0.0527 - val_accuracy: 0.9854\n",
            "Epoch 179/180\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9891 - val_loss: 0.0973 - val_accuracy: 0.9708\n",
            "Epoch 180/180\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9928 - val_loss: 0.0803 - val_accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(x, y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgGq017-XDQJ",
        "outputId": "f92084d2-0394-473e-ec3c-9cf09539ad9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9845\n",
            "accuracy: 98.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training history\n",
        "\n",
        "# list all data in history\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k2rxRJbXLGL",
        "outputId": "c1182a1e-983c-47b2-a9c9-0997abb2239f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "0ojNmIBGXORX",
        "outputId": "402d6158-74db-43ac-8436-a46e4dde0ebd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9K0M6n1JXT8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter Tuning"
      ],
      "metadata": {
        "id": "JYyDp2-EXc8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = fire.iloc[:,0:-1]\n",
        "Y = fire['size_category']"
      ],
      "metadata": {
        "id": "9Z_TIFOCXhQ5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "metadata": {
        "id": "bQgulW47Xk8a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_standardized).describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "0CkpkxhUXuBU",
        "outputId": "619b612c-5a19-49e6-806e-79cb1f263ea6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    count          mean       std        min       25%       50%       75%  \\\n",
              "0   517.0 -1.754024e-15  1.000969 -13.045818 -0.080635  0.173229  0.408960   \n",
              "1   517.0  3.070830e-16  1.000969  -1.715608 -0.660665 -0.040203  0.492739   \n",
              "2   517.0  7.387171e-17  1.000969  -2.179108 -0.444828  0.469119  0.669663   \n",
              "3   517.0 -3.865380e-17  1.000969  -1.980578 -0.553595 -0.136477  0.390409   \n",
              "4   517.0  2.005703e-16  1.000969  -2.876943 -0.584238  0.070821  0.674164   \n",
              "5   517.0  3.362881e-16  1.000969  -1.796637 -0.692456 -0.140366  0.534411   \n",
              "6   517.0 -2.676776e-16  1.000969  -2.021098 -0.736124 -0.009834  0.492982   \n",
              "7   517.0 -2.841054e-16  1.000969  -0.073268 -0.073268 -0.073268 -0.073268   \n",
              "8   517.0 -1.274502e-16  1.000969  -0.202020 -0.202020 -0.193843 -0.098709   \n",
              "9   517.0  4.874674e-17  1.000969  -0.443576 -0.443576 -0.443576 -0.443576   \n",
              "10  517.0 -1.868267e-16  1.000969  -0.408709 -0.408709 -0.408709 -0.408709   \n",
              "11  517.0 -2.238699e-16  1.000969  -0.440449 -0.440449 -0.440449 -0.440449   \n",
              "12  517.0 -6.098711e-17  1.000969  -0.474467 -0.474467 -0.474467 -0.474467   \n",
              "13  517.0 -1.004999e-16  1.000969  -0.365748 -0.365748 -0.365748 -0.365748   \n",
              "14  517.0  2.405125e-17  1.000969  -0.375873 -0.375873 -0.375873 -0.375873   \n",
              "15  517.0 -3.843906e-17  1.000969  -0.341512 -0.341512 -0.341512 -0.341512   \n",
              "16  517.0 -1.344293e-16  1.000969  -0.133103 -0.133103 -0.133103 -0.133103   \n",
              "17  517.0  2.473843e-16  1.000969  -0.743339 -0.743339 -0.743339  1.345282   \n",
              "18  517.0  7.179943e-16  1.000969  -0.133103 -0.133103 -0.133103 -0.133103   \n",
              "19  517.0 -1.933764e-16  1.000969  -0.200603 -0.200603 -0.200603 -0.200603   \n",
              "20  517.0 -2.260174e-17  1.000969  -0.062318 -0.062318 -0.062318 -0.062318   \n",
              "21  517.0  1.352883e-17  1.000969  -0.256865 -0.256865 -0.256865 -0.256865   \n",
              "22  517.0  1.169277e-16  1.000969  -0.184391 -0.184391 -0.184391 -0.184391   \n",
              "23  517.0  2.265542e-16  1.000969  -0.341512 -0.341512 -0.341512 -0.341512   \n",
              "24  517.0 -2.596515e-16  1.000969  -0.062318 -0.062318 -0.062318 -0.062318   \n",
              "25  517.0  1.443075e-16  1.000969  -0.044023 -0.044023 -0.044023 -0.044023   \n",
              "26  517.0  6.253326e-16  1.000969  -0.172860 -0.172860 -0.172860 -0.172860   \n",
              "27  517.0  4.024290e-16  1.000969  -0.706081 -0.706081 -0.706081  1.416268   \n",
              "\n",
              "          max  \n",
              "0    1.007353  \n",
              "1    2.819865  \n",
              "2    1.261610  \n",
              "3   10.335381  \n",
              "4    2.484195  \n",
              "5    3.417549  \n",
              "6    3.007063  \n",
              "7   21.572284  \n",
              "8   16.951110  \n",
              "9    2.254407  \n",
              "10   2.446730  \n",
              "11   2.270410  \n",
              "12   2.107630  \n",
              "13   2.734120  \n",
              "14   2.660475  \n",
              "15   2.928152  \n",
              "16   7.512952  \n",
              "17   1.345282  \n",
              "18   7.512952  \n",
              "19   4.984977  \n",
              "20  16.046807  \n",
              "21   3.893103  \n",
              "22   5.423261  \n",
              "23   2.928152  \n",
              "24  16.046807  \n",
              "25  22.715633  \n",
              "26   5.785038  \n",
              "27   1.416268  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2c47016-1298-4eb1-8c16-c2263fb397df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.754024e-15</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-13.045818</td>\n",
              "      <td>-0.080635</td>\n",
              "      <td>0.173229</td>\n",
              "      <td>0.408960</td>\n",
              "      <td>1.007353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>517.0</td>\n",
              "      <td>3.070830e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-1.715608</td>\n",
              "      <td>-0.660665</td>\n",
              "      <td>-0.040203</td>\n",
              "      <td>0.492739</td>\n",
              "      <td>2.819865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>517.0</td>\n",
              "      <td>7.387171e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-2.179108</td>\n",
              "      <td>-0.444828</td>\n",
              "      <td>0.469119</td>\n",
              "      <td>0.669663</td>\n",
              "      <td>1.261610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-3.865380e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-1.980578</td>\n",
              "      <td>-0.553595</td>\n",
              "      <td>-0.136477</td>\n",
              "      <td>0.390409</td>\n",
              "      <td>10.335381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>517.0</td>\n",
              "      <td>2.005703e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-2.876943</td>\n",
              "      <td>-0.584238</td>\n",
              "      <td>0.070821</td>\n",
              "      <td>0.674164</td>\n",
              "      <td>2.484195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>517.0</td>\n",
              "      <td>3.362881e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-1.796637</td>\n",
              "      <td>-0.692456</td>\n",
              "      <td>-0.140366</td>\n",
              "      <td>0.534411</td>\n",
              "      <td>3.417549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-2.676776e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-2.021098</td>\n",
              "      <td>-0.736124</td>\n",
              "      <td>-0.009834</td>\n",
              "      <td>0.492982</td>\n",
              "      <td>3.007063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-2.841054e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>21.572284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.274502e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.202020</td>\n",
              "      <td>-0.202020</td>\n",
              "      <td>-0.193843</td>\n",
              "      <td>-0.098709</td>\n",
              "      <td>16.951110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>517.0</td>\n",
              "      <td>4.874674e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.443576</td>\n",
              "      <td>-0.443576</td>\n",
              "      <td>-0.443576</td>\n",
              "      <td>-0.443576</td>\n",
              "      <td>2.254407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.868267e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.408709</td>\n",
              "      <td>-0.408709</td>\n",
              "      <td>-0.408709</td>\n",
              "      <td>-0.408709</td>\n",
              "      <td>2.446730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-2.238699e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.440449</td>\n",
              "      <td>-0.440449</td>\n",
              "      <td>-0.440449</td>\n",
              "      <td>-0.440449</td>\n",
              "      <td>2.270410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-6.098711e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.474467</td>\n",
              "      <td>-0.474467</td>\n",
              "      <td>-0.474467</td>\n",
              "      <td>-0.474467</td>\n",
              "      <td>2.107630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.004999e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.365748</td>\n",
              "      <td>-0.365748</td>\n",
              "      <td>-0.365748</td>\n",
              "      <td>-0.365748</td>\n",
              "      <td>2.734120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>517.0</td>\n",
              "      <td>2.405125e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.375873</td>\n",
              "      <td>-0.375873</td>\n",
              "      <td>-0.375873</td>\n",
              "      <td>-0.375873</td>\n",
              "      <td>2.660475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-3.843906e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>2.928152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.344293e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>7.512952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>517.0</td>\n",
              "      <td>2.473843e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.743339</td>\n",
              "      <td>-0.743339</td>\n",
              "      <td>-0.743339</td>\n",
              "      <td>1.345282</td>\n",
              "      <td>1.345282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>517.0</td>\n",
              "      <td>7.179943e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>-0.133103</td>\n",
              "      <td>7.512952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-1.933764e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.200603</td>\n",
              "      <td>-0.200603</td>\n",
              "      <td>-0.200603</td>\n",
              "      <td>-0.200603</td>\n",
              "      <td>4.984977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-2.260174e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>16.046807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>517.0</td>\n",
              "      <td>1.352883e-17</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.256865</td>\n",
              "      <td>-0.256865</td>\n",
              "      <td>-0.256865</td>\n",
              "      <td>-0.256865</td>\n",
              "      <td>3.893103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>517.0</td>\n",
              "      <td>1.169277e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.184391</td>\n",
              "      <td>-0.184391</td>\n",
              "      <td>-0.184391</td>\n",
              "      <td>-0.184391</td>\n",
              "      <td>5.423261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>517.0</td>\n",
              "      <td>2.265542e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>-0.341512</td>\n",
              "      <td>2.928152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>517.0</td>\n",
              "      <td>-2.596515e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>-0.062318</td>\n",
              "      <td>16.046807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>517.0</td>\n",
              "      <td>1.443075e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.044023</td>\n",
              "      <td>-0.044023</td>\n",
              "      <td>-0.044023</td>\n",
              "      <td>-0.044023</td>\n",
              "      <td>22.715633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>517.0</td>\n",
              "      <td>6.253326e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.172860</td>\n",
              "      <td>-0.172860</td>\n",
              "      <td>-0.172860</td>\n",
              "      <td>-0.172860</td>\n",
              "      <td>5.785038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>517.0</td>\n",
              "      <td>4.024290e-16</td>\n",
              "      <td>1.000969</td>\n",
              "      <td>-0.706081</td>\n",
              "      <td>-0.706081</td>\n",
              "      <td>-0.706081</td>\n",
              "      <td>1.416268</td>\n",
              "      <td>1.416268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2c47016-1298-4eb1-8c16-c2263fb397df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2c47016-1298-4eb1-8c16-c2263fb397df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2c47016-1298-4eb1-8c16-c2263fb397df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning of Hyperparameters :- Batch Size and Epochs"
      ],
      "metadata": {
        "id": "pJ2xMEiXYFwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "jNPqXTgiYID0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=28, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=Adam(lr=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "kTsHmtu9YLhf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "# Define the grid search parameters\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEHR7NKMYOLz",
        "outputId": "fb7bd81a-e549-4ca6-cc37-dcc78e1c8a25"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=1.000 total time=   2.9s\n",
            "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.856 total time=   1.7s\n",
            "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.806 total time=   1.4s\n",
            "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.883 total time=   1.3s\n",
            "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.883 total time=   1.4s\n",
            "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   5.9s\n",
            "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.856 total time=   5.9s\n",
            "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.893 total time=   3.7s\n",
            "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.932 total time=   5.9s\n",
            "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.922 total time=   3.6s\n",
            "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=  11.5s\n",
            "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.856 total time=  11.0s\n",
            "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.893 total time=   6.7s\n",
            "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.922 total time=  11.0s\n",
            "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.903 total time=  11.2s\n",
            "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.990 total time=   1.3s\n",
            "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.817 total time=   1.1s\n",
            "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.825 total time=   1.1s\n",
            "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.835 total time=   1.1s\n",
            "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.854 total time=   1.4s\n",
            "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   3.4s\n",
            "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.875 total time=   2.9s\n",
            "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.893 total time=   2.3s\n",
            "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.913 total time=   3.4s\n",
            "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.883 total time=   2.4s\n",
            "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   3.7s\n",
            "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.885 total time=   3.9s\n",
            "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.893 total time=   5.9s\n",
            "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.893 total time=   3.9s\n",
            "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.903 total time=   3.7s\n",
            "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.524 total time=   1.1s\n",
            "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa3e10ab4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.767 total time=   1.3s\n",
            "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa3e9b67950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.806 total time=   1.0s\n",
            "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=1.000 total time=   1.5s\n",
            "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.865 total time=   1.6s\n",
            "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.893 total time=   2.0s\n",
            "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.903 total time=   2.0s\n",
            "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.893 total time=   2.0s\n",
            "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   2.5s\n",
            "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.875 total time=   3.3s\n",
            "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.903 total time=   3.3s\n",
            "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.903 total time=   2.4s\n",
            "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.864 total time=   2.8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHPrqgRlYXE_",
        "outputId": "80214ee5-1ca3-42d6-a1f7-7c2548450cbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.9206683993339538, using {'batch_size': 10, 'epochs': 50}\n",
            "0.8857169508934021,0.06379661648208658 with: {'batch_size': 10, 'epochs': 10}\n",
            "0.9206683993339538,0.04773207755925867 with: {'batch_size': 10, 'epochs': 50}\n",
            "0.9148431539535522,0.04776624233549265 with: {'batch_size': 10, 'epochs': 100}\n",
            "0.8644510865211487,0.06417309871385972 with: {'batch_size': 20, 'epochs': 10}\n",
            "0.9128640770912171,0.04533315433257131 with: {'batch_size': 20, 'epochs': 50}\n",
            "0.9147871375083924,0.042998252148959276 with: {'batch_size': 20, 'epochs': 100}\n",
            "0.7694174766540527,0.15163979340077074 with: {'batch_size': 40, 'epochs': 10}\n",
            "0.9109409928321839,0.04626133410542883 with: {'batch_size': 40, 'epochs': 50}\n",
            "0.9089805841445923,0.04801900616813698 with: {'batch_size': 40, 'epochs': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning of Hyperparameters:- Learning rate and Drop out rate"
      ],
      "metadata": {
        "id": "y98aojTYaNAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(4,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSxKi6KtaPrS",
        "outputId": "436230ed-1475-4317-fa0e-92fdb94fa1f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   1.7s\n",
            "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.750 total time=   1.5s\n",
            "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   1.1s\n",
            "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.680 total time=   1.1s\n",
            "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.709 total time=   0.9s\n",
            "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.670 total time=   1.0s\n",
            "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.709 total time=   0.9s\n",
            "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.767 total time=   1.4s\n",
            "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.779 total time=   1.1s\n",
            "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.767 total time=   0.9s\n",
            "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.680 total time=   0.9s\n",
            "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.864 total time=   0.9s\n",
            "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   1.1s\n",
            "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.699 total time=   1.5s\n",
            "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.670 total time=   1.1s\n",
            "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.757 total time=   1.1s\n",
            "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.806 total time=   1.3s\n",
            "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.923 total time=   2.0s\n",
            "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.750 total time=   1.3s\n",
            "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.524 total time=   1.1s\n",
            "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.777 total time=   1.0s\n",
            "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.699 total time=   1.1s\n",
            "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   1.5s\n",
            "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   1.0s\n",
            "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.923 total time=   1.0s\n",
            "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.680 total time=   1.0s\n",
            "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.738 total time=   1.1s\n",
            "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.699 total time=   1.1s\n",
            "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   1.4s\n",
            "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.524 total time=   1.1s\n",
            "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.709 total time=   1.2s\n",
            "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.718 total time=   1.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27mKwJ3KaUMg",
        "outputId": "b4d9e763-f78f-4255-921a-0a0bcfa597d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.8179051518440247, using {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7325242638587952,0.15400213076804797 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.7791262149810791,0.11546869320286117 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.8179051518440247,0.10819747184228658 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.796601939201355,0.11065831732339193 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.7346153855323792,0.12886912385121263 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.7579163551330567,0.08642003412272611 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.7402912616729737,0.15210528121652053 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ],
      "metadata": {
        "id": "6UFFSiNtbE5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "# Defining the model\n",
        "\n",
        "def create_model(activation_function,init):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grids = dict(activation_function = activation_function,init = init)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGf0_fdObFq3",
        "outputId": "99f1765a-7cd0-4150-e997-d8252e7b7b0a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   2.2s\n",
            "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.750 total time=   1.6s\n",
            "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   1.2s\n",
            "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   1.1s\n",
            "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   1.2s\n",
            "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   1.5s\n",
            "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.2s\n",
            "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   1.1s\n",
            "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   1.2s\n",
            "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   1.2s\n",
            "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   1.2s\n",
            "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   1.4s\n",
            "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.750 total time=   1.8s\n",
            "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   1.8s\n",
            "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.680 total time=   1.4s\n",
            "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.699 total time=   1.0s\n",
            "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   1.1s\n",
            "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   1.0s\n",
            "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   1.0s\n",
            "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.6s\n",
            "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   1.0s\n",
            "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.981 total time=   1.0s\n",
            "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.750 total time=   1.2s\n",
            "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.641 total time=   1.1s\n",
            "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.718 total time=   1.2s\n",
            "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   1.0s\n",
            "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.592 total time=   1.5s\n",
            "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.689 total time=   1.0s\n",
            "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.728 total time=   1.2s\n",
            "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   1.2s\n",
            "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   1.1s\n",
            "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.933 total time=   1.1s\n",
            "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.621 total time=   1.4s\n",
            "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.680 total time=   1.2s\n",
            "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.709 total time=   1.2s\n",
            "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.952 total time=   1.1s\n",
            "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.631 total time=   1.1s\n",
            "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.699 total time=   1.0s\n",
            "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.689 total time=   1.0s\n",
            "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.4s\n",
            "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   1.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfkRJBvBbLc-",
        "outputId": "7f4295aa-8bbb-4d2b-8447-283bbf258a8c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.753920829296112, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.753920829296112,0.11921194358802965 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.7519417405128479,0.13530024368458718 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.7384801983833313,0.10575299519780877 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.7442681074142456,0.11048396668651816 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning of Hyperparameter :-Number of Neurons in activation layer"
      ],
      "metadata": {
        "id": "J2Pn9n8Xbj2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model(neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc-vjH5lbkkR",
        "outputId": "189779ab-edd2-4ea9-e552-e47df785c43a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   1.7s\n",
            "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.563 total time=   1.0s\n",
            "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.709 total time=   1.1s\n",
            "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.952 total time=   1.1s\n",
            "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   1.2s\n",
            "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.612 total time=   1.1s\n",
            "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.680 total time=   1.6s\n",
            "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.718 total time=   1.1s\n",
            "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   1.0s\n",
            "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.621 total time=   1.1s\n",
            "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.680 total time=   1.2s\n",
            "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.718 total time=   1.1s\n",
            "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.933 total time=   1.2s\n",
            "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.750 total time=   1.3s\n",
            "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.612 total time=   1.0s\n",
            "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.680 total time=   1.5s\n",
            "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.728 total time=   1.1s\n",
            "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.962 total time=   1.2s\n",
            "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.750 total time=   1.1s\n",
            "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.621 total time=   1.1s\n",
            "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.699 total time=   1.2s\n",
            "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.981 total time=   1.1s\n",
            "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.602 total time=   1.0s\n",
            "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.699 total time=   1.6s\n",
            "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.933 total time=   1.2s\n",
            "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.750 total time=   1.2s\n",
            "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.621 total time=   1.1s\n",
            "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.689 total time=   1.1s\n",
            "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.689 total time=   1.0s\n",
            "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.962 total time=   1.0s\n",
            "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.641 total time=   1.1s\n",
            "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.689 total time=   1.1s\n",
            "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.699 total time=   1.1s\n",
            "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.933 total time=   1.6s\n",
            "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.750 total time=   1.2s\n",
            "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.689 total time=   1.7s\n",
            "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.689 total time=   2.1s\n",
            "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.718 total time=   2.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atPYwHw5b5n8",
        "outputId": "2a183830-3b3b-48f1-fee1-d0b9b45328a4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.7559559345245361, using {'neuron1': 16, 'neuron2': 8}\n",
            "0.7402912497520446,0.14395476155459408 with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.7423263549804687,0.11451570735468528 with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.7538834929466247,0.13032511669013647 with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.7404219388961792,0.10722880532994467 with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.7423076868057251,0.11709282639757794 with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.7422703504562378,0.12839741946125677 with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.7365384578704834,0.10619122957153963 with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.7481329321861268,0.11219701723833136 with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.7559559345245361,0.09116880422886003 with: {'neuron1': 16, 'neuron2': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with optimum values of Hyperparameters"
      ],
      "metadata": {
        "id": "0EWi0yEwcelb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16,input_dim = 28,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 16,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "model.fit(X_standardized,Y)\n",
        "\n",
        "# Predicting using trained model\n",
        "\n",
        "y_predict = model.predict(X_standardized)\n",
        "\n",
        "# Printing the metrics\n",
        "print(accuracy_score(Y,y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILj3-gJRcfkn",
        "outputId": "86a2d2d8-31a8-4c49-b218-e07d4de6ec15"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7775628626692457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters all at once"
      ],
      "metadata": {
        "id": "DNnxoP4DcyXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "bSadYGQYc0eA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OjMLe3qc5AI",
        "outputId": "0b90cae4-f507-40a9-d2a6-dba8570cd71d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grid search parameters\n",
        "\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]"
      ],
      "metadata": {
        "id": "kMo_mk-Xc7vk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)"
      ],
      "metadata": {
        "id": "34k8kCZZc-wk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)\n",
        "\n",
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "gTDcL0EWdBtv",
        "outputId": "19186867-6575-4c14-a15c-8abcb33eff5c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.845 total time=   7.9s\n",
            "[CV 1/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-026cadddf3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_standardized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Summarize the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5nnHlgWJdGcA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}